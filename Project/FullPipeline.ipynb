{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General structure taken from Jon's A4 Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # needed for plotting\n",
    "import numpy as np # numpy is primary library for numeric array (and matrix) handling\n",
    "import scipy as sp\n",
    "from scipy import stats, signal\n",
    "import random\n",
    "from sklearn import svm # needed for svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import kurtosis, skew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Capture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live Capture for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing and Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add preprocessing functions here if needed\n",
    "def preprocess(rawSignal):\n",
    "    \n",
    "    # Add preprocessing functions here if needed\n",
    "    return rawSignal\n",
    "\n",
    "class LiveSound:\n",
    "    def __init__(self, data, sampleRate):\n",
    "        self.sound = data\n",
    "        self.sound_float = data.astype(float)\n",
    "        self.sound_p = preprocess(data)\n",
    "        self.sample_rate = sampleRate\n",
    "        \n",
    "        self.soundClassification = None\n",
    "\n",
    "\n",
    "class SoundTrial:\n",
    "    def __init__(self, soundName, trialNum, filenameWithPath):\n",
    "        self.soundName = soundName\n",
    "        self.trialNum = trialNum\n",
    "        self.filenameWithPath = filenameWithPath\n",
    "        self.filename = os.path.basename(filenameWithPath)\n",
    "        \n",
    "        sampleRate, data = wavfile.read(filenameWithPath)\n",
    "    \n",
    "        self.sound = data\n",
    "        self.sound_float = data.astype(float)\n",
    "        self.sound_p = preprocess(data)\n",
    "        self.sample_rate = sampleRate\n",
    "    \n",
    "    def __str__(self):\n",
    "         return \"'{}' : Trial {} from {}\".format(self.soundName, self.trialNum, self.filename)\n",
    "      \n",
    "    \n",
    "    \n",
    "class SoundSet:\n",
    "    def __init__(self, sound_sample_path, map_sounds_to_trials):\n",
    "        self.path = sound_sample_path\n",
    "        self.map_sounds_to_trials = map_sounds_to_trials \n",
    "        \n",
    "    # returns the base path\n",
    "    def get_base_path(self):\n",
    "        return os.path.basename(os.path.normpath(self.path))\n",
    "    \n",
    "    # returns the number of sounds\n",
    "    def get_num_sounds(self):\n",
    "        return len(self.map_sounds_to_trials)\n",
    "    \n",
    "    # returns the total number of trials\n",
    "    def get_total_num_of_trials(self):\n",
    "        numTrials = 0 \n",
    "        for soundName, trialSet in self.map_sounds_to_trials.items():\n",
    "            numTrials = numTrials + len(trialSet)\n",
    "        return numTrials\n",
    "    \n",
    "    # returns a sorted list of gesture names\n",
    "    def get_sound_names_sorted(self):\n",
    "        return sorted(self.map_sounds_to_trials.keys())\n",
    "    \n",
    "\n",
    "    # THESE HAVEN'T BEEN CHANGED YET ****************************\n",
    "    # returns the longest trial (based on num rows recorded and not clock time)\n",
    "    def get_longest_trial(self):\n",
    "        longest_trial_length = -1\n",
    "        longest_trial = None\n",
    "        for gesture_name, trial_list in self.map_gestures_to_trials.items():\n",
    "            for trial in trial_list:\n",
    "                if longest_trial_length < len(trial.accel.x):\n",
    "                    longest_trial_length = len(trial.accel.x)\n",
    "                    longest_trial = trial\n",
    "        return longest_trial\n",
    "    \n",
    "\n",
    "    \n",
    "    # returns trials for a gesture name\n",
    "    def get_trials_for_gesture(self, gesture_name):\n",
    "        return self.map_gestures_to_trials[gesture_name]\n",
    "    \n",
    "    # creates an aggregate signal based on *all* trials for this gesture\n",
    "    # TODO: in future could add in an argument, which takes a list of trial nums\n",
    "    # to use to produce aggregate signal\n",
    "    def create_aggregate_signal(self, gesture_name, signal_var_name):\n",
    "        trials = self.get_trials_for_gesture(gesture_name)\n",
    "        aggregate_signal = None\n",
    "        trial_signals = []\n",
    "        trial_signals_original = []\n",
    "        first_trial = None\n",
    "        first_trial_signal = None\n",
    "        \n",
    "        max_length = -1\n",
    "        for trial in trials:\n",
    "            trial_signal = getattr(trial.accel, signal_var_name)\n",
    "            if max_length < len(trial_signal):\n",
    "                max_length = len(trial_signal)\n",
    "            \n",
    "        for i in range(len(trials)):\n",
    "            if i == 0:\n",
    "                first_trial = trials[i]\n",
    "                trial_signal = getattr(first_trial.accel, signal_var_name)\n",
    "                trial_signal_mod = np.copy(trial_signal)\n",
    "\n",
    "                trial_signals.append(trial_signal_mod)\n",
    "                trial_signals_original.append(trial_signal)\n",
    "                \n",
    "                array_length_diff = max_length - len(trial_signal_mod)\n",
    "                trial_signal_mod = np.pad(trial_signal_mod, (0, array_length_diff), 'mean')  \n",
    "\n",
    "                aggregate_signal = trial_signal_mod\n",
    "                first_trial_signal = trial_signal_mod\n",
    "            else:\n",
    "\n",
    "                cur_trial = trials[i]\n",
    "                cur_trial_signal = getattr(trial.accel, signal_var_name) \n",
    "                trial_signals_original.append(cur_trial_signal)\n",
    "                \n",
    "                array_length_diff = max_length - len(cur_trial_signal)\n",
    "                cur_trial_signal_mod = np.pad(cur_trial_signal, (0, array_length_diff), 'mean') \n",
    "\n",
    "                cur_trial_signal_mod = get_aligned_signal_cutoff_and_pad(cur_trial_signal_mod, first_trial_signal)\n",
    "                trial_signals.append(cur_trial_signal_mod)\n",
    "                aggregate_signal += cur_trial_signal_mod\n",
    "        \n",
    "        mean_signal = aggregate_signal / len(trial_signals) \n",
    "        return mean_signal\n",
    "\n",
    "    # Returns the minimum number of trials across all gestures (just in case we accidentally recorded a \n",
    "    # different number. We should have the same number of trials across all gestures)\n",
    "    def get_min_num_of_trials(self):\n",
    "        minNumTrials = -1 \n",
    "        for gestureName, trialSet in self.map_gestures_to_trials.items():\n",
    "            if minNumTrials == -1 or minNumTrials > len(trialSet):\n",
    "                minNumTrials = len(trialSet)\n",
    "        return minNumTrials\n",
    "    \n",
    "    # get random gesture name\n",
    "    def get_random_gesture_name(self):\n",
    "        gesture_names = list(self.map_gestures_to_trials.keys())\n",
    "        rand_gesture_name = gesture_names[random.randint(0, len(gesture_names) - 1)]\n",
    "        return rand_gesture_name\n",
    "    \n",
    "    # get random trial\n",
    "    def get_random_trial(self):\n",
    "        rand_gesture_name = self.get_random_gesture_name()\n",
    "        print(\"rand_gesture_name\", rand_gesture_name)\n",
    "        trials_for_gesture = self.map_gestures_to_trials[rand_gesture_name]\n",
    "        return trials_for_gesture[random.randint(0, len(trials_for_gesture) - 1)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # prettify the str()\n",
    "    def __str__(self):\n",
    "         return \"'{}' : {} sounds and {} total trials\".format(self.path, self.get_num_sounds(), self.get_total_num_of_trials())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import ntpath\n",
    "import os\n",
    "\n",
    "# From: https://stackoverflow.com/questions/800197/how-to-get-all-of-the-immediate-subdirectories-in-python\n",
    "def get_immediate_subdirectories(a_dir):\n",
    "    return [name for name in os.listdir(a_dir)\n",
    "            if os.path.isdir(os.path.join(a_dir, name))]\n",
    "\n",
    "# Currently excludes any filenames with 'fulldatastream' in the title\n",
    "def find_wav_filenames( path_to_dir, suffix=\".wav\" ):\n",
    "    filenames = listdir(path_to_dir)\n",
    "    return [ filename for filename in filenames if filename.endswith( suffix )]\n",
    "\n",
    "def parse_and_create_sound_trials( path_to_dir ):\n",
    "    wavFilenames = find_wav_filenames(path_to_dir)\n",
    "    \n",
    "    print(\"Found {} wav files in {}\".format(len(wavFilenames), path_to_dir))\n",
    "    \n",
    "    mapSoundNameToTrialList = dict()\n",
    "    mapSoundNameToMapSampleNum = dict()\n",
    "    for wavFilename in wavFilenames:\n",
    "        \n",
    "        # parse filename into meaningful parts\n",
    "        filenameNoExt = os.path.splitext(wavFilename)[0];\n",
    "        filenameParts = filenameNoExt.split(\"_\")\n",
    "            \n",
    "        soundName = filenameParts[0]\n",
    "        sampleNum = filenameParts[1]\n",
    "        fileName = \"filename\"\n",
    "        #print(\"soundName={} sampleNum={}\".format(soundName, sampleNum))\n",
    "        \n",
    "        \n",
    "        if soundName not in mapSoundNameToMapSampleNum:\n",
    "            mapSoundNameToMapSampleNum[soundName] = dict()\n",
    "            \n",
    "        if sampleNum not in mapSoundNameToMapSampleNum[soundName]:\n",
    "            mapSoundNameToMapSampleNum[soundName][sampleNum] = dict()\n",
    "            \n",
    "        mapSoundNameToMapSampleNum[soundName][sampleNum][fileName] = wavFilename\n",
    "\n",
    "        #print(mapSoundNameToMapSampleNum)\n",
    "    \n",
    "    print(\"Found {} sounds\".format(len(mapSoundNameToMapSampleNum)))\n",
    "   \n",
    "\n",
    "    # Now we need to loop through the data and sort each sound set by timems values \n",
    "    # (so that we have trial 1, 2, 3, etc. in order)\n",
    "    for soundName, mapSampleNumToFile in mapSoundNameToMapSampleNum.items():\n",
    "        soundTrialNum = 0\n",
    "        mapSoundNameToTrialList[soundName] = list()\n",
    "        for sampleNum in sorted(mapSampleNumToFile.keys()):\n",
    "            mapSampleToFile = mapSampleNumToFile[sampleNum]\n",
    "            \n",
    "            filenameWithPath = os.path.join(path_to_dir, mapSampleToFile[\"filename\"])\n",
    "            soundTrial = SoundTrial(soundName, soundTrialNum, filenameWithPath)\n",
    "            mapSoundNameToTrialList[soundName].append(soundTrial)\n",
    "            \n",
    "            soundTrialNum = soundTrialNum + 1\n",
    "        \n",
    "        print(\"Found {} trials for '{}'\".format(len(mapSoundNameToTrialList[soundName]), soundName))\n",
    "\n",
    "    return mapSoundNameToTrialList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "class MapSoundSets:\n",
    "    def __init__(self,rootSoundSamplePath=\"./SoundSamples\", targetDirWord=\"thresholdStop\"):\n",
    "        #sets map_sound_sets\n",
    "        self.load_data(rootSoundSamplePath, targetDirWord)\n",
    "        \n",
    "    \n",
    "    def load_data(self, rootSoundSamplePath, targetDirWord):\n",
    "\n",
    "        print(get_immediate_subdirectories(rootSoundSamplePath))\n",
    "        sound_sample_paths = get_immediate_subdirectories(rootSoundSamplePath)\n",
    "\n",
    "        self.map_sound_sets = dict()\n",
    "        self.selected_sound_set = None\n",
    "\n",
    "        for sound_sample_path in sound_sample_paths:\n",
    "            path_to_sound_sample = os.path.join(rootSoundSamplePath, sound_sample_path)\n",
    "            print(\"\\nReading in:\", path_to_sound_sample)\n",
    "            map_sounds_to_trials = parse_and_create_sound_trials(path_to_sound_sample)\n",
    "            sound_set = SoundSet(sound_sample_path, map_sounds_to_trials)\n",
    "            self.map_sound_sets[sound_set.get_base_path()] = sound_set\n",
    "            if targetDirWord in sound_sample_path:\n",
    "                    self.selected_sound_set = sound_set\n",
    "\n",
    "        if self.selected_sound_set is not None:\n",
    "            print(\"\\nThe selected sound set:\", self.selected_sound_set)\n",
    "        \n",
    "\n",
    "    def get_sound_set_with_str(self, targetStr):\n",
    "        for base_path, sound_set in self.map_sound_sets.items():\n",
    "            if targetStr in base_path:\n",
    "                #print(\"set: \",sound_set)\n",
    "                return sound_set\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playing with FFT specgrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "# This is the simplest possible SVM using only a few features but gives you a sense of the overall approach\n",
    "# Some nice resources:\n",
    "#  - A very simple classification example using scikit: \n",
    "#     https://dbaumgartel.wordpress.com/2014/03/10/a-scikit-learn-example-in-10-lines/\n",
    "#  - A nice video overview of SVM: https://youtu.be/N1vOgolbjSc\n",
    "#  - Official sci-kit learn: http://scikit-learn.org/stable/modules/svm.html\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools\n",
    "from scipy.stats import kurtosis, skew\n",
    "\n",
    "# Returns a feature vectof for the given trial\n",
    "def extract_features_example(sample):\n",
    "\n",
    "    # Play around with features to extract and use in your model\n",
    "    # Brainstorm features, visualize ideas, try them, and iterate\n",
    "    # This is likely where you will spend most of your time :)\n",
    "    # This is the \"feature engineering\" component of working in ML\n",
    "    features = []\n",
    "\n",
    "    # Length\n",
    "    #features.append(len(trial.sound))\n",
    "\n",
    "    features.append(np.mean(sample.sound))\n",
    "\n",
    "    return features\n",
    "\n",
    "class TrainedModel:\n",
    "\n",
    "    \n",
    "    def __init__(self, selectedSet, modelType = \"svm\", targetedString=\"Test\"):\n",
    "        self.selected_sound_set = selectedSet\n",
    "        self.numSounds = self.selected_sound_set.get_num_sounds()\n",
    "        self.numTrialsTotal = self.selected_sound_set.get_total_num_of_trials()\n",
    "\n",
    "\n",
    "        trainingData = []\n",
    "        self.classLabels = np.array([])\n",
    "\n",
    "        # build training data for this set of folds\n",
    "        #for trainingSample in self.selected_sound_set.map_sounds_to_trials:\n",
    "        #    for trainingSoundName, trainingTrial in trainingSample.items():\n",
    "        for trainingSoundName, trainingTrials in self.selected_sound_set.map_sounds_to_trials.items():\n",
    "            for trial in trainingTrials:\n",
    "                features = extract_features_example(trial)\n",
    "                trainingData.append(features)\n",
    "                self.classLabels = np.append(self.classLabels, trainingSoundName)\n",
    "\n",
    "        # Playing with scaling data, code taken from 5/21 lecture slides\n",
    "        self.trainingData = np.array(trainingData)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit(trainingData)\n",
    "        self.training_data_scaled = self.scaler.transform(trainingData)\n",
    "\n",
    "        self._trainModel(modelType)\n",
    "\n",
    "    def _trainModel(self, modelType):\n",
    "        if modelType == \"svm\":\n",
    "            # Here, we train SVM, the 'rbf' kernal is default\n",
    "            # if you use rbf, need to set gamma and C parameters\n",
    "            # play around with different kernels, read about them, and try them. What happens?\n",
    "            # see: \n",
    "            # - https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html#sphx-glr-auto-examples-svm-plot-rbf-parameters-py\n",
    "            # - https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "            self.model = svm.SVC(kernel='linear', gamma=0.01) # kernel='rbf'\n",
    "            self.model.fit(np.array(self.training_data_scaled), self.classLabels) \n",
    "        \n",
    "    def classifySample(self, liveSoundSample):\n",
    "        features = np.array(extract_features_example(liveSoundSample))\n",
    "        features_scaled = self.scaler.transform([features])\n",
    "        \n",
    "        prediction = self.model.predict(features_scaled)\n",
    "        return prediction\n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thresholdStop', '6secSample']\n",
      "\n",
      "Reading in: ./SoundSamples/thresholdStop\n",
      "Found 51 wav files in ./SoundSamples/thresholdStop\n",
      "Found 8 sounds\n",
      "Found 6 trials for 'GarbageDisposal'\n",
      "Found 7 trials for 'MicrowaveDoorClose'\n",
      "Found 6 trials for 'MicrowaveDoorOpen'\n",
      "Found 6 trials for 'MicrowaveEnding'\n",
      "Found 8 trials for 'Toaster'\n",
      "Found 6 trials for 'FridgeDoorOpen'\n",
      "Found 6 trials for 'CoffeeGrinder'\n",
      "Found 6 trials for 'FridgeDoorClose'\n",
      "\n",
      "Reading in: ./SoundSamples/6secSample\n",
      "Found 49 wav files in ./SoundSamples/6secSample\n",
      "Found 8 sounds\n",
      "Found 6 trials for 'GarbageDisposal'\n",
      "Found 6 trials for 'MicrowaveDoorClose'\n",
      "Found 6 trials for 'MicrowaveDoorOpen'\n",
      "Found 6 trials for 'MicrowaveEnding'\n",
      "Found 7 trials for 'Toaster'\n",
      "Found 6 trials for 'FridgeDoorOpen'\n",
      "Found 6 trials for 'CoffeeGrinder'\n",
      "Found 6 trials for 'FridgeDoorClose'\n",
      "\n",
      "The selected sound set: 'thresholdStop' : 8 sounds and 51 total trials\n",
      "['Toaster']\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "map_sound_sets = MapSoundSets()\n",
    "trained_model = TrainedModel(map_sound_sets.selected_sound_set, targetedString=\"thresholdStop\")\n",
    "\n",
    "test = SoundTrial(\"coffee\", 0, \"./SoundSamples/6secSample/CoffeeGrinder_0_captured.wav\")\n",
    "testLive = LiveSound(test.sound, test.sample_rate)\n",
    "\n",
    "print(trained_model.classifySample(testLive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_sound_set_with_str' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-c2bfc17e2b27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtargeted_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Test\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mselected_sound_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sound_set_with_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargeted_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0msound_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselected_sound_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_sounds_to_trials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_sound_set_with_str' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Feature extraction testing\n",
    "\n",
    "targeted_string = \"Test\"\n",
    "selected_sound_set = get_sound_set_with_str(targeted_string)\n",
    "sound_trials = selected_sound_set.map_sounds_to_trials\n",
    "\n",
    "\n",
    "soundName = sound_trials[\"FridgeDoor\"]\n",
    "features, labels = np.empty((0,193)), np.empty(0)\n",
    "for trial in soundName:\n",
    "    s = trial.sound_float\n",
    "    r = trial.sample_rate\n",
    "    \n",
    "    stft = np.abs(librosa.stft(s))\n",
    "    \n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=s, sr=r, n_mfcc=40).T,axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=r).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(s, sr=r).T,axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=r).T,axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(s), sr=r).T,axis=0)\n",
    "    \n",
    "    print(type(tonnetz))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
